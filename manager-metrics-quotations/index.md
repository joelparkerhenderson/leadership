# Manager metrics quotations

<blockquote>

Managers need to evaluate the people assigned to them, objectively, and they need to give an unbiased and objectively verifiable score. This means something they can measure, such as metrics or verifiable goals. Not being able to objectively justify a score is a problem that no manager wants to have, as this is a major liability.

A manager might be fully aware that you unblocked half your team members throughout the year with critical help, and that you are the go-to guy to solve critical issues. But if your team members close twice the tickets you did, they will have trouble justifying you are contributing as much as them.

</blockquote>

<blockquote>

Automated reporting dashboards start to cause damage where they are allowed to become visible by higher-ups in the org. A dashboard is immensely powerful for the immediate manager to know how their team is doing, identify problems and work with the members to resolve those problems. As with many things, the numbers on a dashboard must be read with context. The closer you are to that team, the better.

The moment the dashboard is accessed by higher ups, several things happen: The devs become scrutinized by higher-ups that do not have all the context to make sense of the numbers, the manager is rendered ineffective because the knowledge and power they had while reporting to their superiors is taken away, and upper management will inevitably start caring about the numbers on the dashboard, and nothing else.

</blockquote>

<blockquote>

The metrics I find useful are things like trends before and after a change. For example, if lots of PRs are taking a long time to get through review because the descriptions don't get filled in well, I want to look at the time code spends in review before and after updating the PR template. Or before that, I want to see which teams have code in review for less time so I can look at their PR process and suggest changes to slower teams that the faster teams have already implemented. If a team is doing the same stuff as other teams but their typical PR size is much bigger I want to know if they have fewer stories that they should be breaking down further. And so on.

None of this is data I don't have a gut feel for, but having real numbers is useful for making a case for change. People don't always believe instinct. It's harder to argue with a well-designed graph.

</blockquote>

<blockquote>

Some metrics are either misleading or gameable to the point of being useless. But you'd imagine some tools might be actually useful for a manager? Then the performance reviews. Obviously everyone hates them. I hate them. But how do you keep large orgs of thousands of people with varying motives, moods and ability from descending into chaos?

</blockquote>

<blockquote>

Managers don't spike on technical problems of unpredictable depth and don't do code reviews. I've seen wishful thinking that they did, but in practice, they don't. How can they tell if someone is genuinely stuck on a harder-than-expected problem or is simply full of shit? Verbally ask around for opinions from ICs closer to the subject matter? But that's the same or worse as an informal 360, or a perf review.

</blockquote>

<blockquote>

The metrics tell you one thing, but how to interpret it requires you to know what people are actually doing. And if you do know that then you don't need the metrics. Add to that, I don't think I know anyone that could be trusted to not misinterpret the metrics. It is a great way to reinforce what you believe, you can take your gut feeling and finding a way to see it in the data. But that isn't helpful either.

</blockquote>

<blockquote>

We don’t expose data more granular than at team level. Ever. Quite a few line managers would come to me asking for “personal metrics”, and even engineers in the team were super interested in the data. My argument was personal metrics are toxic and invite misuse. Misuse generates mistrust.

You want to see where are bottlenecks, you want to have measurable targets for how technical work is done and how it correlates to business goals and KPIs. You want to offer teams metrics of their delivery my process so they can take the info and implement improvements whenever they see fit, and have a data driven conversation with the business.  

But teams are the minimum unit of ownership, we stop the instrumentation there. Sure, a team’s performance ultimately links to individuals, but that is the manager’s job to figure out.

</blockquote>

<blockquote>

I’ve helped build out or steer these sorts of systems a number of times and usually management behaves themselves during the adoption and honeymoon phases but then erode the trust later on by trying to use the system to determine PIP or promotion.

Devs who have seen this behavior before tend to push back hard on adoption, and then invest the absolute minimum effort in using these tools. The tools tend to be built wrong often enough to encourage that slide into toxicity. 

</blockquote>

<blockquote>

Good managers are humans and are subject to emotions and biases that they don't even realise they carry around. The only things which bring objectivity are data and good processes.

You should measure events, but you should have the intent that you want to "understand" what is going on, instead of policing people. Data can reveal a lot, like conflicting work patterns, burn-out indicators, problems in communications etc. Not all metrics are bad.

You should combine objective data with subjective feedback, as well as more context such as life events (marriage, becoming a parent etc) to understand how people work.

Processes should enhance focus on outcomes, rather than activity. Frameworks such as OKRs are hard to implement correctly, but they do let you focus on business outcomes. The problem with knowledge work is that you cannot measure it with activities alone. Trying to bridge OKRs with activity metrics as well as subjective feedback can be helpful.

</blockquote>

<blockquote>

Hybrid or remote work is a larger trend that began much before covid, and while back to office mandates might make it seem that the trend is loosing steam, it is not. There will be more remote work in coming years, and that makes understanding your peers' work even more difficult.

</blockquote>

<blockquote>

Managers should understand if employees are effective or not. Employees should understand the goals and objectives of the organization. There should be an alignment on what the expectations are and how people are graded and these tools should be applied before the evaluation and information should be provided to employess on how they are doing on a regular basis.

I’ve definitely worked at organizations that are totally unorganized and it’s totally unclear what the objectives are and they will just call you up and give you different objectives every day and then the performance review addresses totally different objectives from what we’ve been actually doing the entire period.

</blockquote>

<blockquote>

The job of a manager is: 1. Ensure members of the group know what each other are doing. 2. Ensure members of the team know where the team is going. 3. Act as direct report in another team that has another manager that does the same.

</blockquote>

<blockquote>

Collaboration requires communication. In a hierarchy, a manager is a fan-in/out point. It is essential that a manager knows what their team members are doing to effectively perform their role.

</blockquote>

<blockquote>

I don't think you should make the metrics the end all be all (Goodhart's law), but metrics is certainly helpful if you can figure out who might be doing literally NOTHING for hours on end vs. someone who is productive at some level. 

</blockquote>

<blockquote>
 

Metrics can certainly point out "smoke" where there might be someone struggling and then you can be an actual manager and figure it out case by case.

</blockquote>

<blockquote>

Metrics are indicators, one of many. if you are producing zero code vs your peers and your job is to program it doesn't mean you are unproductive, but at least someone can talk to you about it and clarify vs. just guessing with zero data.

</blockquote>

<blockquote>

Managers are people too, despite of what Dilbert will have you believe. They need help, support, and tools. It's true that many tools and frameworks are sold as magic pills that solve all the problems. Metrics are one of those tools that are often misrepresented. I think that many of the tools are helpful, if used skillfully.

</blockquote>

<blockquote>

You can't manage what you can't see. You see your team through your direct interactions with them. You see what they do through the artifacts that they produce. You learn about them from others - hear-say, praise, complaints, and gossip. You also get another perspective through various metrics. You need to combine multiple ways of seeing a team to have a more-complete picture. Take any of them away, and you're a little more blind.

</blockquote>

<blockquote>

There was a time I was running a 10+ team and was executing scrum by the book, not really understanding much of it at start. Meetings felt weird and generally it was very intense time. But after some time a few things clicked in my head: I could plan with some certainty without bothering people, and execution was falling between min/max planned capacity, everyone was aware of pretty much everything, even in 'other places' where they were not actively contributing, everyone learned to estimate their work based on complexity. And above all, after leaving the place and working in a few different shops, when I look at the code quality produced in that place I'm still impressed 

</blockquote>

<blockquote>

If you're at the point that you need 360 reviews (mind you that many companies do them but don't need them), because you don't trust middle management to not play politics for themselves, then your company culture is already rotten and will not get fixed by doing 360 reviews.

